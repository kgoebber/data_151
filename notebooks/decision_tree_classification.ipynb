{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6f0ccb-ce11-4dd0-83ad-a84707b26bd6",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229375c-3b2d-4635-af49-8e58171ab784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb8952-c0f1-4f01-9723-89e030169bde",
   "metadata": {},
   "source": [
    "## Skikit-Learn Decision Trees\n",
    "\n",
    "The main Decision Tree Classifier in Scikit Learn is the `DecisionTreeClassifier()`.\n",
    "\n",
    "There are several parameters that you can set for your decision tree model in Scikit Learn too. Here are a few of the more interesting ones to play around with to try and get some better results:\n",
    "* **max_depth**: The max depth of the tree where we will stop splitting the nodes. This is similar to controlling the maximum number of layers in a deep neural network. Lower will make your model faster but not as accurate; higher can give you accuracy but risks overfitting and may be slow.\n",
    "* **min_samples_split**: The minimum number of samples required to split a node. We discussed this aspect of decision trees above and how setting it to a higher value would help mitigate overfitting.\n",
    "* **max_features**: The number of features to consider when looking for the best split. Higher means potentially better results with the tradeoff of training taking longer.\n",
    "* **min_impurity_split**: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold. This can be used to tradeoff combating overfitting (high value, small tree) vs high accuracy (low value, big tree).\n",
    "* **presort**: Whether to presort the data to speed up the finding of best splits in fitting. If we sort our data on each feature beforehand, our training algorithm will have a much easier time finding good values to split on.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html#decision-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977fc472-5fb5-4d5f-879f-de2a3aa09e85",
   "metadata": {},
   "source": [
    "## Example #1\n",
    "Let's work with our toy example from when we first thought about classification. We'll use our four inputs for training a decision tree (weather outlook, temperature, humidity, and wind) to predict if we would play outside or not.\n",
    "\n",
    "We'll have to do a bit of preprocessing to get our values to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f85a4e-7713-44ac-9165-c37bfe0aa6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features\n",
    "outlook = ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain',\n",
    "           'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain']\n",
    "temp = ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild',\n",
    "        'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild']\n",
    "humidity = ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High',\n",
    "            'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High']\n",
    "wind = ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak',\n",
    "        'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong']\n",
    "\n",
    "# Assigning target vector\n",
    "play = [\"Don't Play\", \"Don't Play\", \"Play\", \"Play\", \"Play\", \"Don't Play\",\n",
    "        \"Play\", \"Don't Play\", \"Play\", \"Play\", \"Play\", \"Play\", \"Play\", \"Don't Play\"]\n",
    "\n",
    "#creating labelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "outlook_encoded=le.fit_transform(outlook)\n",
    "print(f\"Weather: {outlook_encoded}\")\n",
    "\n",
    "# Converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "print(f\"Temp: {temp_encoded}\")\n",
    "\n",
    "# Converting string labels into numbers\n",
    "humidity_encoded=le.fit_transform(humidity)\n",
    "print(f\"Humidity: {humidity_encoded}\")\n",
    "\n",
    "# Converting string labels into numbers\n",
    "wind_encoded=le.fit_transform(wind)\n",
    "print(f\"Wind: {wind_encoded}\")\n",
    "\n",
    "# Convert target strings into numbers (0 = No, 1 = Yes)\n",
    "label=le.fit_transform(play)\n",
    "print(f\"Play: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004965e6-2087-45b9-87fc-abdd6ff89489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinig weather and temp into single listof tuples\n",
    "features = np.vstack((outlook_encoded, temp_encoded, humidity_encoded, wind_encoded)).T\n",
    "\n",
    "classification_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Train our decision tree (tree induction + pruning)\n",
    "tree_model = classification_tree.fit(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be131c-aa58-4934-a96b-1545490d6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some dictionaries linking the string value with the encoded value\n",
    "# This is done using a dictionary comprehension\n",
    "outlook_dictionary = {key:value for key, value in zip(outlook, outlook_encoded)}\n",
    "temperature_dictionary = {key:value for key, value in zip(temp, temp_encoded)}\n",
    "humidity_dictionary = {key:value for key, value in zip(humidity, humidity_encoded)}\n",
    "wind_dictionary = {key:value for key, value in zip(wind, wind_encoded)}\n",
    "predict_outcomes = {key:value for key, value in zip(label, play)}\n",
    "\n",
    "# Weather Possibilities: Sunny, Overcast, Rainy\n",
    "# Temp Possibilities: Hot, Mild, Cool\n",
    "# Humidity Possibilities: High, Normal\n",
    "# Wind Possibilities: Weak, Strong\n",
    "new_outlook = outlook_dictionary['Rain']\n",
    "new_temp = temperature_dictionary['Hot']\n",
    "new_humidity = humidity_dictionary['High']\n",
    "new_wind = wind_dictionary['Weak']\n",
    "\n",
    "ypred = tree_model.predict([[new_outlook, new_temp, new_humidity, new_wind]])\n",
    "print(f'The model predicts: {predict_outcomes[ypred[0]]}')\n",
    "\n",
    "yprob = tree_model.predict_proba([[new_outlook, new_temp, new_humidity, new_wind]])\n",
    "print(f\"Predicted Probability of Don't Play: {yprob[0, 0]*100:.2f}%\")\n",
    "print(f\"Predicted Probability of Play: {yprob[0, 1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4931ae-ecf7-4e29-ba75-f481f4916f21",
   "metadata": {},
   "source": [
    "One of the benefits of the Decision Tree is that we can visualize the tree graphically. Here we'll use the graphviz module to make a nice looking tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f2ad1-a736-4153-aaeb-84edc7a63618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(tree_model, out_file=None, \n",
    "                           feature_names=['Outlook', 'Temp', 'Humidity', 'Wind'],  \n",
    "                           class_names=['Play', 'Dont Play'],  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21da0f6-4faa-4060-9993-96d9466b3711",
   "metadata": {},
   "source": [
    "## Example #2\n",
    "\n",
    "Now let's work with our Iris dataset and only train our model on a subset of our total data so we can validate our model based on the held back data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cbe540-1e86-4ea4-a06f-26d0c5c4b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our dataset\n",
    "iris_data = load_iris()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(iris_data.data, iris_data.target)\n",
    "\n",
    "# Initialize our decision tree object\n",
    "classification_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Train our decision tree (tree induction + pruning)\n",
    "classification_tree = classification_tree.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36da24-9779-40fc-9d5c-34be0421db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(classification_tree, out_file=None, \n",
    "                           feature_names=iris_data.feature_names,  \n",
    "                           class_names=iris_data.target_names,  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph\n",
    "#graph.render(\"iris\", view=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70432cc5-4cb3-4f29-98f6-165b125dfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = classification_tree.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa28d07-ad01-4be5-bce2-d5ada28c33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8e884-f8af-456c-bca9-4eea1df2531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(metrics.confusion_matrix(ytest, ypred), annot=True, cmap=plt.cm.BuPu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49960412-dd60-48d7-9791-7612a6f04900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
