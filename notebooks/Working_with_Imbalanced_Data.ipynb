{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4db789-f601-4583-be76-12cb44e276e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5721e9-1f14-4652-8c30-2e974cad278c",
   "metadata": {},
   "source": [
    "# Imbalanced Data Preprocessing\n",
    "\n",
    "Strategies for balancing highly imbalanced datasets:\n",
    "* Oversample\n",
    "   - Oversample the minority class to balance the dataset\n",
    "   - Can create synthetic data based on the minority class\n",
    "* Undersample\n",
    "   - Remove majority class data (not preferred)\n",
    "* Weight Classes\n",
    "   - Use class weights to make minority class data more prominent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68afc31-dc1f-4faf-86c2-ebd93a1323d7",
   "metadata": {},
   "source": [
    "Let's use the red wine dataset to start with to demonstrate a highly imbalanced data set with very few high and low quality wine ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d407d7-799b-4154-9e56-b800ee28777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8133b1c-995c-429a-958c-61e0cee25568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2bf6b-16ad-4cad-a007-679397d17623",
   "metadata": {},
   "source": [
    "Set the features to use for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b3a1d-18f7-41ee-826a-0b3ac445fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['volatile acidity', 'citric acid', 'sulphates', 'alcohol']]\n",
    "#features = df.drop(columns='quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c1d62-c4fa-4814-b4e6-02e64e07d848",
   "metadata": {},
   "source": [
    "Set the target value for our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b8793-cfe5-4355-9aab-da31ceca4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5ce96-584f-42e3-9410-7b4323fa5f43",
   "metadata": {},
   "source": [
    "Split the dataset into a training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384d1372-53e4-4570-9e39-2ca94339f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytrue = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75532f-9b70-496c-ac9c-fa78d14f371f",
   "metadata": {},
   "source": [
    "Visualize the imbalanced nature of the training data set outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446b7d2-3812-4012-9523-e0326fc526ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = ytrue.value_counts()\n",
    "count.plot.bar()\n",
    "plt.ylabel('Number of records')\n",
    "plt.xlabel('Target Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272ef14-7508-4008-be7c-63091f37a158",
   "metadata": {},
   "source": [
    "## Base Model - Imbalanced Data\n",
    "\n",
    "Using a simple Decision Tree Classifier to demonstrate the changes in prediction quality based on using different techniques to deal with imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d957d3-a829-4399-869e-e279a81fe76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "print(f'Accuracy Score: {metrics.accuracy_score(ytrue, y_pred)}')\n",
    "print(f'Precision Score: {metrics.precision_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'Recall Score: {metrics.recall_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score: {metrics.f1_score(ytrue, y_pred, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416a65b-eb05-445f-a5d1-aead671369e9",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "\n",
    "Using the Imbalanced-Learn module, which is built on top of scikit learn, there are a number of options for oversampling (and undersampling) your training data. The most basic is the `RandomOverSampler()` function, which has a couple of different options:\n",
    "* `'auto'` (default: `'not majority'`)\n",
    "* `'minority'`\n",
    "* `'not majority'`\n",
    "* `'not minority'`\n",
    "* `'all'`\n",
    "\n",
    "There are also a host of other possibilities to create synthetic data (e.g., SMOTE)\n",
    "\n",
    "https://imbalanced-learn.org/stable/over_sampling.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fdefac-353f-4892-a5ca-600a90ccff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "\n",
    "X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n",
    "\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d3ccc9-32df-45ef-97c4-a87d6d1db49a",
   "metadata": {},
   "source": [
    "Let's look at the resampled data to confirm that we now have a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215629d-137a-4c6a-9381-fdc1986540d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = y_resampled.value_counts()\n",
    "count.plot.bar()\n",
    "plt.ylabel('Number of records')\n",
    "plt.xlabel('Target Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f592917-9a0e-47c9-aaca-cd00bc7fa096",
   "metadata": {},
   "source": [
    "Now let's try our prediction with the oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65cc37-97dd-4618-834d-e4eaa0385f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "print(f'Accuracy Score: {metrics.accuracy_score(ytrue, y_pred)}')\n",
    "print(f'Precision Score: {metrics.precision_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'Recall Score: {metrics.recall_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score: {metrics.f1_score(ytrue, y_pred, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7ca9a-7e8d-406e-8f36-9183495ef317",
   "metadata": {},
   "source": [
    "So from this, we were able to improve the accuracy, precision, and recall of our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3d702-4f0b-4551-8a6c-62d51940c6a6",
   "metadata": {},
   "source": [
    "## Weighting\n",
    "\n",
    "Determining weights are a balance of different factors and partially affected by the size of the imbalance. Scikit Learn has a function to help compute weights to get balanced classes caleed `compute_class_weights` frim the `class_weight` portion of the module.\n",
    "\n",
    "To get the balanced weights use:\n",
    "\n",
    "`class_weights = ‘balanced’`\n",
    "\n",
    "and the model automatically assigns the class weights inversely proportional to their respective frequencies.\n",
    "\n",
    "If the classes are too imbalanced, you might find better success by assigning weights to each class using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9bfea4-b23d-40b7-a37c-41a512855740",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(ytrain)\n",
    "cw = class_weight.compute_class_weight('balanced', classes=classes, y=ytrain)\n",
    "weights = dict(zip(classes, cw))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5dd81-9cd6-435b-8ea7-67dbd97ecbc8",
   "metadata": {},
   "source": [
    "Now let's use our Decision Tree Model with the class weights calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b5068-987a-4cf3-a385-b518c563a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight=weights)\n",
    "\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "y_pred = model.predict(xtest)\n",
    "\n",
    "print(f'Accuracy Score: {metrics.accuracy_score(ytrue, y_pred)}')\n",
    "print(f'Precision Score: {metrics.precision_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'Recall Score: {metrics.recall_score(ytrue, y_pred, average=\"macro\")}')\n",
    "print(f'F1 Score: {metrics.f1_score(ytrue, y_pred, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d907b7-9203-40d6-8a19-2eb1d3a35b97",
   "metadata": {},
   "source": [
    "So improved over our initial model, but not as much as the oversampled model in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7ab9a-f59f-4bf6-b87c-19a2105d8d84",
   "metadata": {},
   "source": [
    "## Credit Card Fraud - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d8834-0a33-474f-a3a1-2279c938c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# normalise the amount column\n",
    "data['normAmount'] = StandardScaler().fit_transform(np.array(data['Amount']).reshape(-1, 1))\n",
    " \n",
    "# drop Time and Amount columns as they are not relevant for prediction purpose\n",
    "data = data.drop(['Time', 'Amount'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874ad35-63dd-4ba0-9fd8-b4d20ff45902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as you can see there are 492 fraud transactions.\n",
    "print(data['Class'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar([0, 1], data['Class'].value_counts(), tick_label=['Not Fraud', 'Fraud'])\n",
    "plt.text(0, 286000, data['Class'].value_counts()[0], ha='center', fontsize=16)\n",
    "plt.text(1, 10000, data['Class'].value_counts()[1], ha='center', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f22ce1-a645-4925-8eca-83b4b99a78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "# split into 70:30 ration\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# describes info about train and test set\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da815f0-885c-45e5-9273-624ca042eb2c",
   "metadata": {},
   "source": [
    "## Base Model - Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8fa48-b634-41a4-a447-63af2138cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression object\n",
    "lr = LogisticRegression()\n",
    " \n",
    "# train the model on train set\n",
    "lr.fit(X_train, y_train.ravel())\n",
    " \n",
    "predictions = lr.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39f2c9-6338-41b4-86ce-ad91f91fc05d",
   "metadata": {},
   "source": [
    "So our prediction leaves a lot to be desired as we have a very low recall of the fraud cases.\n",
    "\n",
    "Let's try our hand at creating some synthetic data for resampling the minority class using SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d78e08-8820-434e-8f5c-3a5fe09557b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy='minority', random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef4867-8b9a-4fbc-b0fd-6f408b1aa686",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(X_train_res, y_train_res)\n",
    "predictions = lr1.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5955ef0-dfa2-4a10-8ffa-8a6c4ae841c8",
   "metadata": {},
   "source": [
    "Our model's recall of fraud cases has improved greatly from our original model and our non-fraud recall has not suffered much at all.\n",
    "\n",
    "We can also use a different threshold for predicting the fraud case. Instead of the standard >0.5 threshold, we could set 0.6 or 0.7 to improve the precision without harming the recall too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc4c54-6a14-4689-b5d3-1eced0000b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lr1.predict_proba(X_test)[:,1]>=0.7).astype(int)\n",
    " \n",
    "# print classification report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15daf17e-1bd3-4ad7-be91-bab04a462c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
