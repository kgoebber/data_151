{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eecfa0-c197-4ab0-81b4-289f291951ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bbe143f-6b17-4c4d-830a-21c8fa1b8f20",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "## Selecting the Best Model\n",
    "\n",
    "Now that we know the basics of validation and cross-validation, let's demonstrate with how it works with model selection and selection of hyperparameters.\n",
    "These issues are some of the most important aspects of the practice of machine learning.\n",
    "\n",
    "Of core importance is the following question: *if our estimator is underperforming, how should we move forward?*\n",
    "There are several possible answers:\n",
    "\n",
    "- Use a more complicated/more flexible model\n",
    "- Use a less complicated/less flexible model\n",
    "- Gather more training samples\n",
    "- Gather more data to add features to each sample\n",
    "\n",
    "The answer to this question is often counter-intuitive.\n",
    "In particular, sometimes using a more complicated model will give worse results, and adding more training samples may not improve your results!\n",
    "The ability to determine what steps will improve your model is what separates the successful machine learning practitioners from the unsuccessful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ff234-514c-41cb-b44b-926a3092eaad",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Validation curves in Scikit-Learn\n",
    "\n",
    "Let's look at an example using cross-validation to compute the validation curve for a class of models to help us find the goldilocks zone between bias and variance.\n",
    "Here we will use a *polynomial regression* model: this is a generalized linear model in which the degree of the polynomial is a tunable parameter.\n",
    "For example, a degree-1 polynomial fits a straight line to the data; for model parameters $a$ and $b$:\n",
    "\n",
    "$$\n",
    "y = ax + b\n",
    "$$\n",
    "\n",
    "A degree-3 polynomial fits a cubic curve to the data; for model parameters $a, b, c, d$:\n",
    "\n",
    "$$\n",
    "y = ax^3 + bx^2 + cx + d\n",
    "$$\n",
    "\n",
    "We can generalize this to any number of polynomial features.\n",
    "In Scikit-Learn, we can implement this with a simple linear regression combined with the polynomial preprocessor.\n",
    "We will use a *pipeline* to string these operations together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309f417-f274-4c5f-9336-e4f8f6b95f0f",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530dc791-37e0-4057-82b6-8f97edd923ff",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now let's create some data to which we will fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edffdce-e93c-4096-a2ce-767983227c8e",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_data(N, err=1.0, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_data(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ce86d-af22-4d4e-ad35-7fca5e2a8bdd",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can now visualize our data, along with polynomial fits of several degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea462bb-b151-444f-a8e1-fd85da2e9f1a",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee4f7a-4a0f-4550-bdfd-b45492479d8d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The knob controlling model complexity in this case is the degree of the polynomial, which can be any non-negative integer.\n",
    "A useful question to answer is this: what degree of polynomial provides a suitable trade-off between bias (under-fitting) and variance (over-fitting)?\n",
    "\n",
    "We can make progress in this by visualizing the validation curve for this particular data and model; this can be done straightforwardly using the ``validation_curve`` convenience routine provided by Scikit-Learn.\n",
    "Given a model, data, parameter name, and a range to explore, this function will automatically compute both the training score and validation score across the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1a478-5eca-40ec-8e44-c790cc3b41f9",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y,\n",
    "                                          param_name='polynomialfeatures__degree',\n",
    "                                          param_range=degree, cv=7,\n",
    "                                          scoring='explained_variance')\n",
    "\n",
    "plt.plot(degree, np.median(train_score, axis=1), color='blue', label='training score')\n",
    "plt.plot(degree, np.median(val_score, axis=1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(np.arange(0, 20, 2))\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e878dbb-710e-4b6c-b2a3-4573e1f75519",
   "metadata": {
    "editable": true
   },
   "source": [
    "This shows precisely the qualitative behavior we expect: the training score is everywhere higher than the validation score; the training score is monotonically improving with increased model complexity; and the validation score reaches a maximum before dropping off as the model becomes over-fit.\n",
    "\n",
    "From the validation curve, we can read-off that the optimal trade-off between bias and variance is found for a third-order polynomial; we can compute and display this fit over the original data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c8703-e721-41dd-ab67-20466513f6c6",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38d44eb-b749-4adc-a456-fef938642c04",
   "metadata": {
    "editable": true
   },
   "source": [
    "Notice that finding this optimal model did not actually require us to compute the training score, but examining the relationship between the training score and validation score can give us useful insight into the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e7f4b-260a-4d12-9314-84ca9e5de05b",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Learning curves in Scikit-Learn\n",
    "\n",
    "Scikit-Learn offers a convenient utility for computing such learning curves from your models; here we will compute a learning curve for our original dataset with a second-order polynomial model and a ninth-order polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a362a11-39aa-494d-aa36-08b0e207ff25",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "for i, degree in enumerate([2, 9]):\n",
    "    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree),\n",
    "                                         X, y, cv=7,\n",
    "                                         train_sizes=np.linspace(0.3, 1, 25))\n",
    "\n",
    "    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score')\n",
    "    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='validation score')\n",
    "    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1],\n",
    "                 color='gray', linestyle='dashed')\n",
    "\n",
    "    ax[i].set_ylim(0, 1)\n",
    "    ax[i].set_xlim(N[0], N[-1])\n",
    "    ax[i].set_xlabel('training size')\n",
    "    ax[i].set_ylabel('score')\n",
    "    ax[i].set_title('degree = {0}'.format(degree), size=14)\n",
    "    ax[i].legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39b220-a907-4181-9555-f58b49cc9ad1",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is a valuable diagnostic, because it gives us a visual depiction of how our model responds to increasing training data.\n",
    "In particular, when your learning curve has already converged (i.e., when the training and validation curves are already close to each other) *adding more training data will not significantly improve the fit!*\n",
    "This situation is seen in the left panel, with the learning curve for the degree-2 model.\n",
    "\n",
    "The only way to increase the converged score is to use a different (usually more complicated) model.\n",
    "We see this in the right panel: by moving to a much more complicated model, we increase the score of convergence (indicated by the dashed line), but at the expense of higher model variance (indicated by the difference between the training and validation scores).\n",
    "If we were to add even more data points, the learning curve for the more complicated model would eventually converge.\n",
    "\n",
    "Plotting a learning curve for your particular choice of model and dataset can help you to make this type of decision about how to move forward in improving your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216309c5-4393-4108-9b84-68ef5bb820ae",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "estimator.get_params()## Validation in Practice: Grid Search\n",
    "\n",
    "The preceding discussion is meant to give you some intuition into the trade-off between bias and variance, and its dependence on model complexity and training set size.\n",
    "In practice, models generally have more than one knob to turn, and thus plots of validation and learning curves change from lines to multi-dimensional surfaces.\n",
    "In these cases, such visualizations are difficult and we would rather simply find the particular model that maximizes the validation score.\n",
    "\n",
    "Scikit-Learn provides automated tools to do this in the grid search module.\n",
    "Here is an example of using grid search to find the optimal polynomial model.\n",
    "We will explore a three-dimensional grid of model features; namely the polynomial degree, the flag telling us whether to fit the intercept, and the flag telling us whether to normalize the problem.\n",
    "This can be set up using Scikit-Learn's ``GridSearchCV`` meta-estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dba282-54a3-445c-8ae5-5e60246b244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential parameters to test\n",
    "PolynomialRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b826b-d273-4606-9be5-5d857031cac3",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(21),\n",
    "              'linearregression__fit_intercept': [True, False],\n",
    "              'polynomialfeatures__interaction_only': [True, False]}\n",
    "\n",
    "grid = GridSearchCV(PolynomialRegression(), param_grid, cv=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d3906-cee0-492b-a289-5f92c7cd8e72",
   "metadata": {
    "editable": true
   },
   "source": [
    "Notice that like a normal estimator, this has not yet been applied to any data.\n",
    "Calling the ``fit()`` method will fit the model at each grid point, keeping track of the scores along the way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71bf7b-a89e-4cc4-9b88-9d0e0cd5f0e4",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106c3bd-320c-43e5-9ab8-164c3eac49fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now that this is fit, we can ask for the best parameters as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d91a2-562e-45d8-b4ff-3243ea52389a",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50750c54-f98f-4d14-95b3-f87ebf997673",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finally, if we wish, we can use the best model and show the fit to our data using code from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4799cde-69f4-474a-b488-b7ddde331fe1",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "\n",
    "plt.scatter(X.ravel(), y)\n",
    "lim = plt.axis()\n",
    "y_test = model.fit(X, y).predict(X_test)\n",
    "plt.plot(X_test.ravel(), y_test);\n",
    "plt.axis(lim);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9d946-97aa-4eb1-b72b-e97d122bb8a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "The grid search provides many more options, including the ability to specify a custom scoring function, to parallelize the computations, to do randomized searches, and more.\n",
    "For information, see the examples in [In-Depth: Kernel Density Estimation](05.13-Kernel-Density-Estimation.ipynb) and [Feature Engineering: Working with Images](05.14-Image-Features.ipynb), or refer to Scikit-Learn's [grid search documentation](http://Scikit-Learn.org/stable/modules/grid_search.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea25119-86a8-459a-a287-6b210868d503",
   "metadata": {},
   "source": [
    "## Model Evaluation - Classification\n",
    "\n",
    "First we'll set up a classification prediction with our Iris dataset using the Gaussian Naive Bayes model, then we'll use some of the common classification metrics to demonstrate how to use those functions.\n",
    "\n",
    "1. Start with model using a single predictor\n",
    "2. Use all available predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c7654-939c-42f5-a1a7-b1978f97fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('https://datahub.io/machine-learning/iris/r/iris.csv')\n",
    "\n",
    "# Create new column to make numeric values of the three classes of irises\n",
    "reclass = {'Iris-setosa': 1, 'Iris-versicolor': 3, 'Iris-virginica': 5}\n",
    "df['reclass'] = df['class'].map(reclass)\n",
    "\n",
    "# First split data into feature (X) and target (y) matrix\n",
    "X_iris = df['sepallength'].values[:, np.newaxis]\n",
    "#X_iris = df.drop(columns=['class', 'reclass'])\n",
    "y_iris = df['class']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris,\n",
    "                                                random_state=1)\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_model = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef30e0-dde3-47a2-97ef-94748d3e69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "print(f'Accuracy Score: {accuracy_score(ytest, y_model)}')\n",
    "print(f'Precision Score: {precision_score(ytest, y_model, average=\"macro\")}')\n",
    "print(f'Recall Score: {recall_score(ytest, y_model, average=\"macro\")}')\n",
    "print(f'F1 Score: {f1_score(ytest, y_model, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40baa1d5-827b-4bbf-8f0b-56ab2a9eee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix(ytest, y_model).T,\n",
    "            xticklabels=model.classes_,\n",
    "            yticklabels=model.classes_,\n",
    "            annot=True, cmap=plt.cm.OrRd)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74719f3a-7b55-4f9f-844f-c6cf874fc8a0",
   "metadata": {},
   "source": [
    "## Model Metrics - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820519e-824b-4757-83ba-c06acea9413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/kgoebber/data_151/main/notebooks/petrol_consumption.csv')\n",
    "\n",
    "X = df[['Petrol_tax', 'Average_income', 'Paved_Highways',\n",
    "       'Population_Driver_licence(%)']]\n",
    "y = df['Petrol_Consumption']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c8f25-bc98-445a-a0dc-25724a09de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(f'Explained Variance Score: {metrics.explained_variance_score(y_test, y_pred)}')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e32ff-14fd-4666-acfc-fec6222d540c",
   "metadata": {},
   "source": [
    "Now apply ridge regression and cross validation to generate a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb97e06-80e5-41ec-aa2a-ea922158224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "cv_regressor = RidgeCV(alphas=[5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1] , cv=5)\n",
    "cv_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c229e2-d22c-4086-8ec4-93342996fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cv_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d8331-e8b6-4173-99d7-b089450c02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Explained Variance Score: {metrics.explained_variance_score(y_test, y_pred)}')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58dad42-f4a7-464e-8607-a3f77ccd12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_regressor.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f0df6-1ea7-46c4-9c08-b0de2bd64f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
