{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "reading_data_and_cleaning_in_pandas.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a469060c-8bcf-43c0-ac00-09a8d036f26b"
      },
      "source": [
        "# Data Manipulation with Pandas"
      ],
      "id": "a469060c-8bcf-43c0-ac00-09a8d036f26b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1288d564-d14d-4390-b3d0-cff720ec74af"
      },
      "source": [
        "In the previous lectures, we dove into NumPy and its ``ndarray`` object, which provides efficient storage and manipulation of dense typed arrays in Python. Here we'll build on this knowledge by looking at the data structures provided by the Pandas library. Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a ``DataFrame``. ``DataFrame``s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data. As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
        "\n",
        "As we saw, NumPy's ``ndarray`` data structure provides essential features for the type of clean, well-organized data typically seen in numerical computing tasks. While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us. Pandas, and in particular its ``Series`` and ``DataFrame`` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
        "\n",
        "Here we will focus on the mechanics of using ``Series``, ``DataFrame``, and related structures effectively."
      ],
      "id": "1288d564-d14d-4390-b3d0-cff720ec74af"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40d7e0ea-c2a3-44e6-976c-51bbed115dd4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "40d7e0ea-c2a3-44e6-976c-51bbed115dd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72a19a9-69b7-4089-9d83-a7eada27f95a"
      },
      "source": [
        "## Reading Data\n",
        "\n",
        "Accessing data is a critical first step in any data science project. Many times data can be obtained in simple delimited (e.g., comma, tab) formats that are relatively easy to read in using functionality built into the Pandas module. There are other formats that data could be in (e.g., json, excel, netCDF, etc.), but we won't focus on those in this course.\n",
        "\n",
        "Pandas Tutorial on Reading Data: https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html\n",
        "\n",
        "Curated data sets (e.g., the Titanic dataset: https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv) are often easy to read as they have well defined column headers and don't require use of any special handling to successfully read them into a notebook.\n",
        "\n",
        "## DataFrame\n",
        "The data object that tabular data is read into with Pandas is known as a `DataFrame` (a commonly used variable name to represent this is `df`). A DataFrame represents a rectangular table of data and contains an ordered collec‐ tion of columns, each of which can be a different value type (numeric, string, boolean, etc.). The DataFrame has both a row and column index; it can be thought of as a dict of `Series` all sharing the same index. Under the hood, the data is stored as one or more two-dimensional blocks rather than a list, dict, or some other collection of one-dimensional arrays. The exact details of DataFrame’s internals are outside the scope of this book."
      ],
      "id": "a72a19a9-69b7-4089-9d83-a7eada27f95a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c611ebee-9438-4937-890e-29f8a063390c"
      },
      "source": [
        "df = pd.read_csv('https://datahub.io/machine-learning/iris/r/iris.csv')"
      ],
      "id": "c611ebee-9438-4937-890e-29f8a063390c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c5f90a0-920e-4ff9-a530-30b284137a57"
      },
      "source": [
        "## Reading a New Dataset\n",
        "\n",
        "Some datasets may contain metadata or additional information somewhere within a file you are attempting to read in. This will likely cause your data to be read in a manner that won't allow it to be successfully used. To demonstrate the use of keyword arguments in reading in a dataset, we'll use the Southern Oscillation Index (SOI) dataset, which is a measure related to El Nino events.\n",
        "\n",
        "The raw dataset can be found at: https://www.cpc.ncep.noaa.gov/data/indices/soi"
      ],
      "id": "7c5f90a0-920e-4ff9-a530-30b284137a57"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09bc7068-3948-4fc2-b8f1-04d6d2c51d1a"
      },
      "source": [
        "df_soi = pd.read_csv('https://www.cpc.ncep.noaa.gov/data/indices/soi')"
      ],
      "id": "09bc7068-3948-4fc2-b8f1-04d6d2c51d1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4083e93-4b21-4332-a7a0-69789c3c9a07"
      },
      "source": [
        ""
      ],
      "id": "c4083e93-4b21-4332-a7a0-69789c3c9a07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "637ce183-5b3c-46e6-b064-6fe47ec27600"
      },
      "source": [
        "Sometimes the way we have read in similar data just won't work. We have to move to an alternative. What do you think are difficulties we would have reading in the SOI data set based on the output above and inspecting the data via the link?"
      ],
      "id": "637ce183-5b3c-46e6-b064-6fe47ec27600"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38466f36-83fa-49a0-a35e-925e3a8158d1"
      },
      "source": [
        ""
      ],
      "id": "38466f36-83fa-49a0-a35e-925e3a8158d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e1661f7-c8df-4527-9cc0-de530c9f11a9"
      },
      "source": [
        ""
      ],
      "id": "1e1661f7-c8df-4527-9cc0-de530c9f11a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d4bc5d0-bf7e-44a8-9028-a941da04a9f5"
      },
      "source": [
        "## Add Calculated Column\n",
        "Let's calculate the average SOI value for each year and add it as a new column to the DataFrame.\n",
        "\n",
        "We can use either methods built into the DataFrame itself or use Numpy functions to aid in the calculation."
      ],
      "id": "0d4bc5d0-bf7e-44a8-9028-a941da04a9f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ba2d1c-fba7-48d8-944d-e547dc31633f"
      },
      "source": [
        ""
      ],
      "id": "c8ba2d1c-fba7-48d8-944d-e547dc31633f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "773802a9-b54f-4d47-8186-b89397766f45"
      },
      "source": [
        "## Operating on Null Values\n",
        "\n",
        "As we have seen, Pandas treats ``None`` and ``NaN`` as essentially interchangeable for indicating missing or null values.\n",
        "To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures.\n",
        "They are:\n",
        "\n",
        "- ``isnull()``: Generate a boolean mask indicating missing values\n",
        "- ``notnull()``: Opposite of ``isnull()``\n",
        "- ``dropna()``: Return a filtered version of the data\n",
        "- ``fillna()``: Return a copy of the data with missing values filled or imputed\n",
        "\n",
        "We will conclude this section with a brief exploration and demonstration of these routines."
      ],
      "id": "773802a9-b54f-4d47-8186-b89397766f45"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "003bfd70-12b4-48d5-8e8f-0fc99c00ef29"
      },
      "source": [
        "### Detecting null values\n",
        "Pandas data structures have two useful methods for detecting null data: ``isnull()`` and ``notnull()``.\n",
        "Either one will return a Boolean mask over the data."
      ],
      "id": "003bfd70-12b4-48d5-8e8f-0fc99c00ef29"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb0eff9a-38db-4382-9693-640e258253ec"
      },
      "source": [
        ""
      ],
      "id": "fb0eff9a-38db-4382-9693-640e258253ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7775e0-963a-4d3d-a241-d4a81ddc1dfc"
      },
      "source": [
        "### Dropping null values\n",
        "\n",
        "In addition to the masking used before, there are the convenience methods, ``dropna()``\n",
        "(which removes NA values) and ``fillna()`` (which fills in NA values). For a ``Series``,\n",
        "the result is straightforward:"
      ],
      "id": "bc7775e0-963a-4d3d-a241-d4a81ddc1dfc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46191d5b-e67c-45d3-ac46-e6747f175e9d"
      },
      "source": [
        ""
      ],
      "id": "46191d5b-e67c-45d3-ac46-e6747f175e9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae7ae44c-bd7a-46b6-9116-86f1804289c5"
      },
      "source": [
        "We cannot drop single values from a ``DataFrame``; we can only drop full rows or full columns.\n",
        "Depending on the application, you might want one or the other, so ``dropna()`` gives a number of options for a ``DataFrame``."
      ],
      "id": "ae7ae44c-bd7a-46b6-9116-86f1804289c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b643b191-ba78-41f5-8c4f-1ebce97586a8"
      },
      "source": [
        ""
      ],
      "id": "b643b191-ba78-41f5-8c4f-1ebce97586a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af46e209-6980-48a7-91df-27e69d7dd717"
      },
      "source": [
        "## Output Refined Datasets\n",
        "We don't ever want to change the raw dataset, so that we can always go back to it in case we need to. Other times we don't want to have to use the time or computer memory to read in ALL of the data, if we are only working with a small subset of rows or columns.\n",
        "\n",
        "So once you have your refined dataset, you may want to save it in a format that you can quickly read it back in to a notebook.\n",
        "\n",
        "As long as your dataset is a DataFrame, there are methods to save in similar formats that Pandas can read including, comma deliminated (csv), excel, and JSON.\n",
        "\n",
        "Let's save our refined SOI dataset as a comma deliminated file with our added columns."
      ],
      "id": "af46e209-6980-48a7-91df-27e69d7dd717"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "222bcf4e-1623-4537-97aa-d6a44d9ecb7e"
      },
      "source": [
        ""
      ],
      "id": "222bcf4e-1623-4537-97aa-d6a44d9ecb7e",
      "execution_count": null,
      "outputs": []
    }
  ]
}